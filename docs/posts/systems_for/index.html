<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Tom Savage">
<meta name="author" content="Studio 3015">
<meta name="dcterms.date" content="2024-04-22">

<title>TRS - Systems for… Collaboration</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../favicon.ico" rel="icon">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">TRS</span>
    </a>
  </div>
          <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About Me</span></a>
  </li>  
</ul>
          <div class="quarto-navbar-tools ms-auto">
</div>
            <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Systems for… Collaboration</h1>
            <p class="subtitle lead">Human-AI Collaboration for the WSA Final Year Graphic Design Degree Show</p>
                                <div class="quarto-categories">
                <div class="quarto-category">Machine Learning</div>
                <div class="quarto-category">Art</div>
                <div class="quarto-category">Visualisation</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Authors</div>
      <div class="quarto-title-meta-contents">
               <p>Tom Savage </p>
               <p>Studio 3015 </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">April 22, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">




<p>This year’s Winchester School of Art final year graphic design degree show will be presented under the <em>Systems for…</em> unification. Each project will be assigned a single word that summarises the <em>system</em> that best summarises the purpose of the project. This post deals with how the <em>system</em> is defined for each project, and how we augment each project using AI.</p>
<div class="page-columns page-full"><p>Previously, I’ve written about human-AI collaboration<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. I believe that methodologies<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> that apply AI as a tool, and that are designed with humans in mind, will be particularly pervasive within the next 10 years across both the arts and engineering. This is the broad theme I have approached this project with.</p><div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;<a href="https://sav.phd/posts/human_in_the_loop/">Expert-Guided Bayesian Optimisation for Human-in-the-loop Experimental Design of Known Systems</a>…<a href="https://sav.phd/posts/transubstantiation/">The Machine Learning Reformation</a></p></li><li id="fn2"><p><sup>2</sup>&nbsp;Application centered methodologies, not foundational work.</p></li></div></div>
<p>We first begin by describing the provided image for use in downstream tasks. This is done using the Anthropic vision API</p>
<div class="cleanbox">
<div class="center">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="cropped_image.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Yoko Ono with Glass Hammer 1967 from HALF-A-WIND SHOW, Lisson Gallery, London, 1967. Photograph © Clay Perry / Artwork © Yoko Ono</figcaption>
</figure>
</div>
</div>
<p><strong>IMAGE DESCRIPTION:</strong> The image shows a woman with long, dark hair wearing a black coat. She is holding what appears to be a wooden walking stick or cane. The black and white photograph creates a striking, somber tone. The woman has a serious expression on her face as she gazes directly at the camera. The image has a thoughtful, introspective quality to it.</p>
</div>
<p>This description is combined with the provided project description, and standard prompt engineering is used to uncover the underlying <em>system</em>.</p>
<p>At the same time, we prompt the LLM to return a physical representation of the system. This will be used later.</p>
<div class="page-columns page-full"><p>Few-shot prompting<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> is used with XML-like tags, and the response is preloaded with a single open-curly bracket to enforce a JSON output. The prompt is as follows:</p><div class="no-row-height column-margin column-container"><li id="fn3"><p><sup>3</sup>&nbsp;Providing a few brief examples of expected inputs + outputs</p></li></div></div>
<div class="cleanbox" style="font-size: 75%;">
<p>Consider these aspects of the information provided, and decide on an interesting word that follows the phase ‘Systems for…’ that describes the project. The word may be unconventional, creative, and importantly emotional; associated to the key ‘system’.</p>
<p>You must also return something physical and visual that represents the word, associated to the key ‘representation’. The representation must be visually striking, interesting, and a single object.</p>
<p>You must only return valid JSON with no extra characters. You must never speculate about the future or potential of the description, only reasoning about the given text as stated.</p>
<p>&lt; examples &gt; &lt; input &gt; Title: Chromatic Fusion: An Immersive Journey Through Color and Emotion In this captivating final year art project, the artist takes viewers on a mesmerizing journey through the realm of color and its profound impact on human emotions. “Chromatic Fusion” is an immersive, multi-sensory installation that combines vibrant, large-scale abstract paintings, interactive light displays, and a meticulously curated soundscape. &lt; /input &gt; &lt; output &gt; {‘system’: ‘Viewing’, ‘explanation’: ‘The project is centered around the act of viewing, suggesting a focus on the visual experience.,’representation’: ‘An eye’} &lt; /output &gt;</p>
<p>&lt; input &gt; Title: The Future of Urban Mobility: A Sustainable Transportation Revolution This ambitious research project explores the future of urban mobility and envisions a sustainable transportation revolution that will transform the way people move through cities. By analyzing current trends in transportation, urban planning, and environmental sustainability, the research team aims to develop innovative solutions that address the challenges of congestion, pollution, and limited access to public transit. &lt; /input &gt; &lt; output &gt; {‘system’: ‘Motion’, ‘explanation’: ‘The project is focused on motion and movement, suggesting a strong emphasis on transportation and mobility.,’representation’: ‘A wheel’} &lt; /output &gt; &lt; /examples &gt;</p>
<p></p>
<p>&lt; input &gt; {project + image description} &lt; output &gt; {</p>
</div>
<p>The resulting physical representation is then used as a prompt within the DALL-2 inpainting API, augmenting the provided image. Here is an example of output and augmented image, choosing to add a pair of scissors representing participation.</p>
<div class="cleanbox">
<p>{“explanation”:” The exhibition highlights Yoko Ono’s groundbreaking approach to audience participation and engagement, inviting visitors to actively encounter and contribute to her artworks.”, “system”: “PARTICIPATION”, “representation”: “A PAIR OF SCISSORS”}</p>
</div>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="cropped_image.png" class="img-fluid"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="generated_image.png" class="img-fluid"></p>
</div>
</div>
</div>
<p>The augmented visual represents the interplay between the visual as created by the student, and the AI’s interpretation of the <em>system</em>.</p>
<div class="page-columns page-full"><p>Finally, we assemble all the human-AI generated content into a visual for the degree show book. To further emphasise the collaborative role, we prompted each student for how <em>human</em>, <em>natural</em>, and <em>mechanistic</em> they believe their project to be. Then, we asked the AI to provide<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> the same set of values between 0-100.</p><div class="no-row-height column-margin column-container"><li id="fn4"><p><sup>4</sup>&nbsp;Through similar few-shot prompting as demonstrated above</p></li></div></div>
<p>These three parameters in turn control the size and location of text as it overlays onto both the augmented visual and the original visual (now combined).</p>
<p>Here, closer text in terms of location and size represents a level of similarity between how AI has determined a project to represented, and what it’s creator has intended.</p>
<div class="center">
<p><img src="collaborative_visual.png" class="img-fluid"></p>
</div>
<p>At every stage, AI has been used as a tool to enhance the representation of the existing project. To not only determine an appropriate <em>system</em>, but to augment a project image, and raise questions about the intended interpretation.</p>
<p>An overview of the information flow is as follows:</p>
<div class="center">
<p><img src="overview.png" class="img-fluid"></p>
</div>




</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>