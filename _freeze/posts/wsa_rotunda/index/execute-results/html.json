{
  "hash": "2ef03ebfdb043e14eedb6379fbd19bf0",
  "result": {
    "markdown": "---\ntitle: \"Context-Aware Generative Lab Identities for Winchester School of Art\"\nsubtitle: \"_The art of life lies in a constant readjustment to our surroundings._ - Kakuzō Okakura\"\nauthor: \"Tom Savage, Studio 3015\"\ndate: \"03/14/2024\"\nformat:\n    html: \n        css: styles.css\n        theme: custom.scss\nfig-cap-location: margin\nreference-location: margin\ncitation-location: margin\nexecute:\n  eval: false\n---\n\n:::{.cleanbox}\nThis post details a consulting/research project for the [Winchester School of Art (WSA)](https://wsarotunda.soton.ac.uk) digital Rotunda platform, alongside [Studio 3015](https://www.studio3015.co.uk/projects/). If you have a similar project or concept, feel free to contact me at tom.savage(at)hotmail.com\n:::\n\n### Context\n\n[The Rotunda](https://wsarotunda.soton.ac.uk) at the Winchester School of Art is a largely digital platform for organizing and presenting research and events. Given the digital nature of the platform, constraints around static design and identity can be relaxed.\n\n:::{#fig-rotunda}\n![](wsa_rotunda.png){width=70%}\n\nThe WSA Rotunda Research Platform.\n:::\n\nThe goal of this project was to enable existing research lab identities to change dynamically in response to specific media such as text and images related to individual projects. Through the use of generative AI, the visual identity for each lab becomes responsive, adapting based on contextual information around specific initiatives.\n\n\n:::{#fig-existing layout-ncol=4}\n\n![](1-logo.png){width=20%}\n\n![](2-logo.png){width=20%}\n\n![](3-logo.png){width=20%}\n\n![](4-logo.png){width=20%}\n\nExisting designs for the E-Textile, Global Smart, Data Image, and Social Practice labs.\n:::\n\n### From Manual to Digital \n\nThe project began by recreating the existing logos for each lab in an automated manner using the [svgpathtools](https://github.com/mathandy/svgpathtools/tree/master) library. This enabled programmatic modification of the logo forms via Python, while also obtaining SVG files by design which can be used within WSA graphics. Each logo is subsequently defined by a series of coordinates stored within a dictionary, enabling easy addition of new labs or modification of existing designs.\n\nFor example, here is the complete specification of the E-textile lab design.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nlogos[\"e-textiles\"] = {}\n\nlogos[\"e-textiles\"][\"small_circles\"] = [\n    (0, 0),(0, 2),(0, 4),(2, 2),(2, 6),\n    (4, 0),(4, 4),(6, 0),(6, 2),(6, 6),\n    (4, 6),(0, 6),(6, 6),\n]\nlogos[\"e-textiles\"][\"big_circles\"] = [(2, 0), (2, 4), (6, 4), (4, 2)]\nlogos[\"e-textiles\"][\"connected\"] = [\n    [(0, 0), (0, 2)],[(0, 2), (2, 2)],[(6, 0), (6, 2)],\n    [(2, 6), (4, 6)],[(0, 6), (2, 6)],[(0, 6), (0, 4)],\n    [(4, 4), (4, 6)],[(4, 6), (6, 6)],\n]\nlogos[\"e-textiles\"][\"white_connected\"] = [\n    [(-1, 3), (2, 3)], \n    [(5, -1), (5, 2)]\n    ]\n```\n:::\n\n\nTo construct a given logo I used this information alongside svgpath tools to build up the representation in Python.\n\n:::{#fig-build layout-ncol=5}\n\n![](base_logo_1.png)\n\n![](base_logo_2.png)\n\n![](base_logo_3.png)\n\n![](base_logo_4.png)\n\n![](base_logo.png)\n\nThe process of creating a logo computationally from the dictionary that defines it.\n:::\n\n\nGiven this level of control and automation over the general design space, the next step was determining how the logos should change in response to context. After some experimentation, two key ways were identified:\n\n1. Individual 'shapes' are allowed to grow and shrink, enabling either a more solid unified form, or a more distributed representation.\n2. Individual 'shapes' are switched from circles to squares, enabling a more digital and less connected form. \n\n:::{#fig-existing layout-ncol=1}\n![](logo_grid.png)\n\nDifferent combinations of parameters and how they affect the base E-textiles lab design.\n:::\n\n\nIt was decided that these two parameters should provide a representation of how **physically distributed a project** is, as well  how **interdisciplinary** a project is respectively.\n\nThese two parameters were chosen to represent how physically distributed a project is, as well as how interdisciplinary it is. By parameterizing the existing designs in this way, each lab's identity can respond to contextual information around projects, while maintaining the overall form and identity in a controlled manner.\n\n### Colour\n\nThe colour of each identity with respect to the project is also inferred based on the content. \nThe colour is allowed to change based on the following content characteristics:\n\n1. Technical content\n2. Philosophical content\n3. Emotional content\n4. Cultural content\n\nThe 'amount' of each descriptor is obtained by prompting a large-language model, and the respective values converted to individual cyan, magenta, yellow, and black values, resulting in a single CMYK colour. \n\n:::{.cleanbox .code-overflow-wrap}\n**Example:**\n\n:::{txt}\n\nCONTENT SCORE: {'technical': '65', 'philosophical': '10', 'emotional': '15', 'cultural': '20'}\n\nCOLOUR EXPLANATION: The text primarily focuses on describing the technical capabilities and facilities of the WSA E-Textile Innovation Lab, including equipment for textile design, manufacturing, and e-textile development. It also mentions the lab's mission of creating innovative and sustainable e-textiles, which has a philosophical aspect. The emotional and cultural content is relatively low, as the text is mainly informative about the lab's operations.\n\nCMYK: [0.636, 0.114, 0.155, 0.196]\n:::\n\n:::{.center}\n![](logo_col.png){width=40%}\n:::\n:::\n\n\n### Inferring Parameters\n\nTo infer the parameters representing the physical distribution and interdisciplinary nature of a project, an LLM is prompted with both a description and image.\n\nThe information flow is as follows:\n\n:::{#fig-information}\n![](information.png)\n\nThe information flow of project description, images, and parameters eventually leading to a given logo.\n:::\n\nSome prompt engineering is performed to ensure that JSON is consistently returned and reliable explanations for the chosen parameters are provided. This includes providing examples of lab descriptions and respective parameters within the prompt as context. When applying image data, the image is first described, and then in a separate call, the description is used to inform the logo.\n\nEach sentiment and subsequent parameter is prompted separately due to recent advances in low-cost, fast LLM inference to ensure that forgetting or context-shift doesn't occur.\n\n### LLM Inference\n\nLLM inference is performed on [Anthropic's Claude 3 Haiku](https://www.anthropic.com/news/claude-3-haiku). It was found to be extremely low cost, fast, and its performance is sufficient to accurately infer the sentiment of project descriptions and images.\n\n:::{.cleanbox}\n**UTC**: 2024-03-14T11:50:31Z\n\n**Model Name**: claude-3-haiku-20240307\n\n**Prompt**: Describe this image.\n\n**Image**:\n\n![](lab-image.png){width=50% fig-align=\"center\"}\n\n\n**Output**: _This image shows various electronic and technical equipment. There is a device that appears to be a test instrument or measurement tool, with knobs and displays. Next to it is a device that looks like a portable audio player or recorder. On the table in front of these devices is a document or diagram labeled \"Code in Line / Rehabilitation Hand-Night\", which seems to be some kind of technical or engineering schematic. There is also a red tool or instrument that appears to be used for testing or working with the equipment._\n\n\n\n**Input Tokens**: 795 ($0.25/1000000 tokens)\n\n**Output Tokens**: 108 ($1.25/1000000 tokens)\n\n**Total Cost**: $0.00033375 (0.03¢)\n\n**Time**: 3.12 (s)\n\n:::\n\n### Creating an Interface\n\nThe goal of the interface for the generative lab identity inference was to make it as simple as possible for those with a non-technical background to use, on any device, including Winchester School of Art teaching and administrative staff, and students. \n\nTo achieve this, the Python implementation was packaged into a Flask app with a basic password-protected front-end. The application is then hosted on Heroku, a cloud-based platform.\nThis exposes the application on the web for anyone to use, protects against the LLM API credits being used by the public, and removes the need to install or interact with code.\n\nThe user is prompted to provide a project title, description, project visual, and the lab itself. This information is then used as previously described to produce an independent lab logo, with explanation.\n\n:::{.center}\n![](app.png)\n:::\n\nThe user is prompted to provide a project title, description, project visual, and the lab itself. \nThis information is then used as previously described to produce an independent lab logo, with explanation. \n\n### Creating a Loading Image\n\nIn order to design a visually interesting graphic for the front end, an image diffusion model was fine-tined. To begin with a new 3D model of _The Rotunda_ was created in AutoCAD.\n\n:::{.center}\n![](above.png){width=25%}\n![](side.png){width=25%}\n\n:::\n\n Using this 3D model a number of synthetic images of the building were created and combinined with an existing dataset of real photographs.\n\n::: {layout-ncol=8}\n\n![](datasets/rotunda_data/below sketchy wireframe.png) \n\n![](datasets/rotunda_data/black and white photograph.jpeg)\n\n![](datasets/rotunda_data/close outside image.jpeg)\n\n![](datasets/rotunda_data/close up render.png)\n\n![](datasets/rotunda_data/dark line wireframe.png)\n\n![](datasets/rotunda_data/dark orthographic render.png)\n\n![](datasets/rotunda_data/mirrored render.png)\n\n![](datasets/rotunda_data/outside image.jpeg)\n\n![](datasets/rotunda_data/photograph.jpeg)\n\n![](datasets/rotunda_data/render.png)\n\n![](datasets/rotunda_data/sketchy wireframe.png)\n\n![](datasets/rotunda_data/upside down photograph.jpeg)\n\n![](datasets/rotunda_data/white render.png)\n\n![](datasets/rotunda_data/wide outside image.jpeg)\n\n![](datasets/rotunda_data/wireframe.png)\n\n![](datasets/rotunda_data/metallic render.png)\n\n:::\n\n\nThis dataset of approximately 40 images was then used to fine-tuned a Stable Diffusion model using _textual inversion_ to learn the concept of _The Rotunda_.\n\n\n\nThis custom token is then used to perform inference (or generation in the context of generative AI) to generate novel representations and views of the building.<br>\n\n:::{.center}\n![](diffusion_output.gif){width=40%}\n:::\n\nThese representations (in the form of a GIF) provide a sense of the technology involved within the lab logo generation tool, this GIF is also displayed whilst inference is being performed in the background.\n\nThe images, whilst individually imperfect, collectively result in a coherent representation.\n\n### Output\n\n<!-- The final procedure looks like this, \n\n:::{.center}\n![](full_example.gif){width=100%}\n:::\n\nAnd corresponding output: -->\n\nAn example final output for a given project within the E-Textiles lab is as follows:\n\n:::{.center}\n![](wsa-res.png){width=70%}\n:::\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}