{
  "hash": "9506dced6ea4a9d22b7aa5d2ea522806",
  "result": {
    "markdown": "---\ntitle: \"Expert-guided Bayesian Optimisation for Human-in-the-loop Experimental Design of Known Systems\"\n\ndate: 2023-10-27\nauthor:\n  - name: Tom Savage\n    orcid: 0000-0001-8715-8369\n    email: t.savage@imperial.ac.uk\n    affiliation: \n      - name: Imperial College London\n        city: London\n        url: www.imperial.ac.uk/people/t.savage\n\n  - name: Antonio del Rio Chanona\n    affiliation: \n      - name: Imperial College London\n        city: London\n# appendix-cite-as: bibtex\t\nnumber-sections: true\nkeywords:\n  - Bayesian Optimisation\n  - Expert Guided\n  - Human-In-The-Loop\n  - Batch\ncategories: [optimisation]\n# google-scholar: true\ncitation: true\nheader-includes:\n  - \\DeclareMathOperator*{\\argmax}{arg\\,max}\n\nbibliography: ref.bib\ntoc: true\n# format:\n#     pdf: default\n#     html: \n#       self-contained: true\n---\n\n## Abstract {.unnumbered}\n\nDomain experts often possess valuable physical insights that are overlooked in fully automated decision-making processes such as Bayesian optimisation.\nIn this article we apply high-throughput (batch) Bayesian optimisation alongside anthropological decision theory to enable domain experts to influence the selection of optimal experiments. \nOur methodology exploits the hypothesis that humans are better at making discrete choices than continuous ones and enables experts to influence critical early decisions. \nAt each iteration we solve an augmented multi-objective optimisation problem across a number of alternate solutions, maximising both the sum of their utility function values and the determinant of their covariance matrix, equivalent to their total variability. \nBy taking the solution at the knee point of the Pareto front, we return a set of alternate solutions at each iteration that have both high utility values and are reasonably distinct, from which the expert selects one for evaluation.\nWe demonstrate that even in the case of an uninformed practitioner, our algorithm recovers the regret of standard Bayesian optimisation.\n\n## Introduction\n\nBayesian optimisation has been successfully applied in a number of complex domains including engineering systems where derivatives are often not available, such as those that involve simulation or propriety software. \nBy removing the human from decision-making processes in favour of maximising statistical quantities such as expected improvement, complex functions can be optimised in an efficient number of samples. \nHowever, these engineering systems are often engaged with by domain experts such as engineers or chemists, and as such the behaviour of the underlying function cannot be considered completely unknown a-priori. \nTherefore, there exists significant scope to take advantage of the benefits of Bayesian optimisation in optimising expensive derivative-free problems, whilst enabling domain experts to inform the decision-making process, putting the human back into the loop. \nBy providing an optimal set of alternatives to an expert to select their desired evaluation, we ensure that any one choice presents information gain about the optimal solution.\nSimultaneously, we ensure the choices are distinct enough to avoid the human making an effective gradient calculation. \nAlternative solution information such as utility function value, predictive output distribution and visualisations are provided to the expert as a pseudo-likelihood. \nThe decision-maker then effectively performs discrete Bayesian reasoning, internally conditioning the provided information with their own prior expertise and knowledge of the solutions provided. \nIn addition to improved convergence (depending on the ability of the domain expert), our methodology enables improved interpretability in higher dimensions, as the decision-maker has the final say in what is evaluated. \nOur approach works with any utility function and NSGA-II [@Deb2002] is applied for multi-objective optimisation, efficiently handling the non-convex utility-space.  \n@fig-overview demonstrates our methodology\n\n![Overview of our methodology, where an augmented batch Bayesian optimisation problem is solved using multi-objective optimisation, providing an expert with a set of alternate solutions.](overview_figure.png){#fig-overview}\n\nBy allowing an expert to influence the experimental design through a discrete decision step, we mitigate the expert needing to make continuous decisions throughout, and do not rely on an expert `prior' of the global optimum that necessarily must be defined before optimisation. \nApproaches that rely on an expert-defined prior may need to redefine this at significant human-cost throughout optimisation in light of new information.\nSimilarly, the expert has no influence over the actual solutions evaluated and the optimisation is merely weighted towards broad regions in solution-space.\n\n## Previous Work \n\n[@Kanarik2023] demonstrated that experts improve the initial convergence in Bayesian optimisation for semiconductor processes. \nHowever, this can be counterproductive in later stages. \nAlgorithmic integration of expert knowledge has been explored [@Liu2022,@hvarfner2022pibo]. \n[@hvarfner2022pibo] and [@Ramachandran2020] use user-defined priors to weight the acquisition function, while [@Liu2022] diminishes this weight over time. \nThese methods are static and don't allow real-time expert input. \n[@BOMuse] allows continuous expert involvement, using a linear Gaussian process to approximate human intuition, achieving sub-linear regret bounds. \n[@av2022human] and [@robot] present similar frameworks, offering alternative solutions for evaluation, with the expert making the final decision latterly in a molecular design setting. \n\n## Method \n\n\n\nWe first maximise a given utility function $\\mathcal{U}$ for a given dataset $\\mathcal{D}_t:= \\{(\\mathbf{x}_i,y_i)\\}_{i=1}^t$:\n\n$$\n   \\mathbf{x}^* = \\argmax_{x\\in\\mathcal{X}\\subseteq\\mathbb{R}^n} \\; \\mathcal{U}(x),\n$$ {#eq-standard-bo}\n\nresulting in the optimal next evaluation, $\\mathbf{x}^*$, in a utility sense.\nLet $p$ be the number of alternate solutions provided to the expert and construct the decision variable matrix $\\mathbf{X} \\in \\mathbb{R}^{(p-1)\\times n}$ by concatenating $p-1$ alternate solutions $\\mathbf{X} := [\\mathbf{x}_1,\\dots,\\mathbf{x}_{p-1}]$.\nWe then define the high-throughput (batch) utility function $\\hat{\\mathcal{U}}$ which is specified as the sum of the individual utilities of alternate solutions within $\\mathbf{X}$\n\n\\begin{align}\n    \\hat{\\mathcal{U}}(\\mathbf{X}) = \\sum_{i=0}^{p-1} \\mathcal{U}(\\mathbf{X}_i).\n\\end{align}\nSimilarly, we introduce $\\hat{\\mathcal{S}}$ as a measure for capturing the variability among both the optimal and alternative solutions.\nSpecifically, let $\\hat{\\mathcal{S}}$ be the determinant of the covariance matrix $K_{\\mathbf{X}_{\\text{aug}}}$ for the augmented set $\\mathbf{X}_{\\text{aug}}= \\mathbf{X} \\cup \\mathbf{x}^*$:\n\\begin{align*}\n \\hat{\\mathcal{S}}(\\mathbf{X},\\mathbf{x}^*) &= |K_{\\mathbf{X_{\\text{aug}}}}| \\\\\n K_{\\mathbf{X}_{\\text{aug}}} &= [k(\\mathbf{X}_{\\text{aug},i},\\mathbf{X}_{\\text{aug},j})]^p_{i,j=1}\n\\end{align*}\n$\\hat{\\mathcal{S}}$ quantifies the 'volume of information' spanned by the alternative solutions $\\mathbf{X}$ as well as the optimal solution $\\mathbf{x}^*$.\nMaximising $\\hat{\\mathcal{U}}$ will result in all alternative solutions proposed being the same as $\\mathbf{x}^*$, that is $[\\mathbf{x}^*_1,\\dots,\\mathbf{x}^*_{p-1}]$.\nContrary to this, maximising $\\hat{\\mathcal{S}}$ will result in a set of solutions that are maximally-spaced both with respect to other alternatives, but also $\\mathbf{x}^*$.\nAt iteration $t$, we then solve the following multi-objective optimisation problem:\n\\begin{align}\\label{multi-objective}\n    [\\mathbf{X}^*_1,\\dots,\\mathbf{X}^*_m] = \\max_{\\mathbf{X}} \\; \\left(\\hat{\\mathcal{U}}(\\mathbf{X};\\mathcal{D}_t),\\hat{\\mathcal{S}}(\\mathbf{X},\\mathbf{x}^*)\\right),\n\\end{align}\nresulting in a set of $m$ solutions along the Pareto front of both objectives. \nFrom this we define $\\mathbf{X}^*_{k}$ as the solution at knee-point of the Pareto front. \nThe $p-1$ solutions contained within $\\mathbf{X}^*_k$ optimally trade off the sum of their utility values, with their variability. \nThis ensures that when provided to an expert, alongside $\\mathbf{x}^*$, any individual solution will have high expected information gain, and the solutions themselves will be distinct enough to ensure the expert isn't made to make an effective gradient calculation.   \nThe practitioner is then made to choose a solution to evaluate from this set of alternatives. \nTo do so, they are provided with information such as the utility value of each solution, expected output distributions (obtained from the Gaussian process), and information regarding previous solutions that they may wish to draw upon. \nIn doing so, the practitioner effectively performs an internal discrete Bayesian reasoning, conditioning previous prior information and expert opinion with the mathematical quantities provided to make an informed decision.\nOur algorithm can be located within the Appendix.\n\n@fig-behav demonstrates the intended behaviour of our approach. We present a one-dimensional case study, optimising a function obtained through sampling a Gaussian process prior, specified by a Matern 5/2 kernel with lengthscale $l=0.5$. In this case study we provide 3 alternatives to an expert, who's choice we select randomly.\nWe provide details of optimisation methods and hyper-parameters within the Appendix.\n\n\n::: {#fig-behav layout-ncol=1}\n\n![The objective function and utility function after 6 function evaluations. The 3 alternative solutions that maximise the solution distance can be seen in red, whilst the black solutions denote those contained within the knee-solution of the high-throughput multi-objective problem. The yellow optimal solution is included alongside these two alternatives to an expert. In this case choice 4 is selected randomly from the 3 alternatives and the optimum.](utility.png){#fig-util}\n\n![The information provided to the expert regarding the three alternative solutions. In this case choice 1 and choice 3 have relatively similar utility values and predicted output distributions to choice 4 (the optimal of the acquisition function). The expert is then allowed to distinguish between these similar solutions in a way the computer cannot through their prior domain knowledge. By conditioning their prior information on the given values, the expert is effectively performing internal Bayesian reasoning.](choices.png){#fig-choices}\n\nA standard iteration of our approach on a one-dimensional case-study.\n:::\n\n## Computational Results & Discussion\n\nTo assess our approach, we benchmark it against standard Bayesian optimisation.\nIn order to incorporate and assess human interaction in an automated manner, we hypothesise a number of different human behaviours.\nThe 'Expert' practitioner represents an ideal, where the best solution (that is the one with the highest true objective value) is always selected. \nEquivalently, to test the performance of our approach under the influence of a practitioner with misaligned knowledge, we present an 'Adversarial' practitioner who consistently selects the solution with the lowest true objective value.\nIn addition, we present a probabilistic practitioner, who selects the solution with the best true objective value with some probability. \nFinally, we present the behaviour of a 'Trusting' practitioner who selects the solution with the largest utility (as these values are presented), equivalent to standard Bayesian optimisation as this solution is obtained through standard single objective optimisation (@eq-standard-bo). \nIn practice, the expert will condition the information provided with their prior beliefs. \nIn our approach this includes information regarding the expected distribution of the objective of each solution, as well as the utility value of each solution. \nWhilst we cannot benchmark real human behaviour due to the random nature of the objective functions, and practical issues, the behaviours described summarise key aspects in order to generate useful insights into our approach, we leave this for future work.\nThe human behaviours applied are summarised within @tbl-behav.\n\n| **Behaviour Type** | **Description** |\n|---|---|\n| Expert | Selects the solution with the best true function value. |\n| Adversarial | Selects the solution with the worst true function value. |\n| Trusting | Selects the solution with the maximum utility value. |\n| p(Best) | Selects the solution with the best true function value with probability p(Best), otherwise selects a random solution. |\n\n: Human Behaviours Applied for Benchmarking {#tbl-behav}\n\nWe perform optimisation over 50 functions, each representing a sample from a Gaussian process prior with lengthscale 0.3 using the upper-confidence bound (UCB) utility function.\n@fig-res demonstrates the average and standard deviation of simple regret, and average regret (both defined within @Garnett2023) for each human behaviour across 1D and 2D objective functions.  \nResults for 5D, and specific functions can be located within the Appendix.\n\n::: {#fig-res layout-ncol=1}\n\n![Average regret quantities over 1D objective functions.](overall_regret_aq_UCB_d_1.png){#fig-1D}\n\n![Average regret quantities over 2D objective functions.](overall_regret_aq_UCB_d_2.png){#fig-2D}\n\nRegret expectation over 50 functions, $f \\sim \\mathcal{GP}(\\mu \\equiv 0, K_M (d,\\nu = 0.3))$ where $K_M$ is the Mat\\'ern 5/2 kernel function. 4 alternate choices are presented to the practitioner, and the utility function $\\mathcal{U}(x)$ used is the upper-confidence bound.\n:::\n\nThe expectation of average regret tends towards zero for all behaviours, indicating empirical convergence. \nFocusing on results from the set of 1D functions, an 'Expert' provides improved convergence than standard Bayesian optimisation ('Trusting') throughout all iterations, with benefits diminishing throughout the later stages, where the standard automated approach recovers the 'Expert' average regret value, confirming previous observations regarding the importance of human input throughout earlier iterations, and conversely diminishing importance of expert opinion during `fine-tuning' @Kanarik2023.\nImproved convergence of simple regret occurs in cases where the practitioner selects the 'best' solution from a set 75\\%, 50\\%, and to a lesser extent 25% of the time out of 4 available choices, similarly reflected in trends across average regret.\nThe results demonstrated in @fig-res indicate the potential for our approach to improve the convergence of Bayesian optimisation even in cases where the practitioner is correct about a decision only partially.\nWhen the expert makes a random selection ($p(\\text{Best}) = 0.25$, for 4 alternate solutions), standard Bayesian optimisation convergence is recovered, indicating the effectiveness of the choices presented by asking a practitioner to select between distinct solutions, each of which individually has a high utility value.\nThis is reflected throughout 1D, 2D and 5D functions.\nOnly in the case where the practitioner actively selects the worst solution (i.e. they are misaligned), is performance worse. \nIn higher-dimensions an adversarial practitioner performs worse, as they are performing inefficient space-filling in an increasingly larger volume before good solutions are found.\n\nThe methodology we present may also be interpreted as an approach for high-throughput/batch Bayesian optimisation, with an additional preference for solutions that are well-distributed throughout the search space.\nOur intention for future work is to benchmark it against other existing batch Bayesian optimisation methodologies @local_pen, including those with similar multi-objective formulations (@Bischl2014,@Habib2016,@robot). \nWe will also investigate to what extent large-language models can perform the selection step.\n\n\n## Appendix {.unnumbered}\n\n### Algorithm {.unnumbered}\n\n\n```{latex}\n\\begin{algorithmic}[1]\n    \\STATE \\textbf{Initialize:} Objective function \\(f\\), Initial data \\(\\mathcal{D}\\), Domain \\(\\mathcal{X}\\) \n    \\STATE Alternative choices \\(p\\), Utility function \\(\\hat{\\mathcal{U}}\\), Variability function \\(\\hat{\\mathcal{S}}\\), Termination Criteria \\\\\n    \\vspace{2mm} % Vertical space\n\n    \\WHILE{Termination Criteria is False}\n        \\STATE \\(\\mathbf{x}^* \\leftarrow \\argmax_{x\\in\\mathcal{X}} \\mathcal{U}(x)\\) \\texttt{ // Standard Bayesian Optimization Step} \\\\\n        \\vspace{2mm} % Vertical space\n\n        \\STATE \\texttt{\\textbf{// Multi-Objective High-Throughput Optimization}} % Bold monospace font for standalone comment\n        \\STATE \\([\\mathbf{X}^*_1,\\dots,\\mathbf{X}^*_m] \\leftarrow \\max_{\\mathbf{X}} (\\hat{\\mathcal{U}}(\\mathbf{X};\\mathcal{D}), \\hat{\\mathcal{S}}(\\mathbf{X},\\mathbf{x}^*))\\) \\\\\n        \\vspace{2mm} % Vertical space\n\n        \\STATE \\(\\mathbf{X}^*_k \\leftarrow \\text{knee}([\\mathbf{X}^*_1,\\dots,\\mathbf{X}^*_m])\\) \\texttt{ // Select Knee-solution} \\\\\n        \\vspace{2mm} % Vertical space\n\n        \\STATE \\texttt{\\textbf{// Expert selects from alternatives and standard optimal}} % Bold monospace font for standalone comment\n        \\STATE \\(\\mathbf{x}_{\\text{eval}} \\leftarrow \\underset{\\mathbf{x} \\in \\mathbf{X}^*_k\\cup \\mathbf{x}^*}{\\text{expert}} \\mathbf{x}\\) \\\\\n        \\vspace{2mm} % Vertical space\n\n        \\STATE \\(\\mathcal{D} \\leftarrow \\{(\\mathbf{x}_{\\text{eval}}, f(\\mathbf{x}_{\\text{eval}}))\\} \\cup \\mathcal{D}\\) \\texttt{ // Update dataset} \\\\\n    \\ENDWHILE\n\\end{algorithmic}\n```\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}